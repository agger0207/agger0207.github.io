<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 经验总结 | 穷小子Agger的技术博客]]></title>
  <link href="http://agger0207.github.io/blog/categories/jing-yan-zong-jie/atom.xml" rel="self"/>
  <link href="http://agger0207.github.io/"/>
  <updated>2016-01-01T18:23:04+08:00</updated>
  <id>http://agger0207.github.io/</id>
  <author>
    <name><![CDATA[Agger]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[工作经历回忆 之 快速性能改进]]></title>
    <link href="http://agger0207.github.io/blog/2015/11/27/gong-zuo-jing-li-hui-yi-zhi-kuai-su-xing-neng-gai-jin/"/>
    <updated>2015-11-27T14:37:29+08:00</updated>
    <id>http://agger0207.github.io/blog/2015/11/27/gong-zuo-jing-li-hui-yi-zhi-kuai-su-xing-neng-gai-jin</id>
    <content type="html"><![CDATA[<p>最近唐巧老师在他的个人博客上开始普及算法相关知识，其中提到熟悉算法和数据结构知识能够帮助我们更好的评估性能问题所在，能够认识到问题的规模对于实际性能的影响，并且举了一个由于问题的规模太小根本就不需要做算法改进的例子，这个我倒是有些体会，也见过一些将代码写得难看加不安全仅仅自以为可以提升性能的做法（比如去掉空指针的判断以为减少了性能开销，其实性能没有节省多少但是带来了crash的风险）；加上自己以前也做过一些性能优化方面的工作，能够很好的认识到，性能优化并不等同于算法优化，所以想回忆一些之前做的一些性能改进的实例，也算是对自己过往工作的一个总结。由于我其实一直是做客户端相关的工作，所以涉及到算法比较少，这些优化经验大部分也和算法优化关系不大, 或者说，这是在介绍自己如何在不改进算法的基础上做的一些性能改进，其实想法都比较简单。</p>

<h2>一 多线程改进数据备份还原性能</h2>

<p>问题描述：做磁盘/文件数据备份，性能慢
一般误解：由于一般过程是，读取数据&ndash;>压缩&ndash;>写入目标文件；所以想到可能是改进压缩算法
实际解决：性能太慢其实仅仅是因为所有的操作都是在一条线程中完成的，即使不压缩，也足够慢呀；所以改进策略就是采用多线程的解决方案，读，压缩，并行即可；无论对于文件备份还是磁盘备份都适合；
进一步优化：
1）多线程压缩；并行后压缩成为真正的瓶颈所在，那么这个时候就可以提高压缩性能了；而比换一个压缩算法更好的方式是，同时用多个线程进行的数据压缩；
2）对部分文件避免压缩：如果是做文件备份，对于图片、视频数据，压缩得不偿失，压缩率低，压缩时间长，不压缩就好了
3）读写线程改善；对同一块磁盘的读写并行，不仅不会提高性能，反而会降低性能；而对不同磁盘的读写并行，是可以提高性能的</p>

<h2>二 遍历磁盘文件树的性能改进</h2>

<p>问题描述：做某个分区的文件备份，需要建立分区的文件树，然后看这些文件是否需要备份，并且需要和已备份的文件树比较，来支持增量备份等一系列的功能；
改进方案：
1 递归改非递归；
如果使用者不分区，那么一个分区里面十几万的文件很正常，这个时候递归遍历并且比较的时候，函数调用会有很多额外的开销，所以仅仅是递归改非递归就可以大大提高这部分性能；
2 避免多次遍历与多次比较；（这个其实是原来的代码写得有问题^_^)
3 利用文件系统的特性：
Windows上有个很火的工具，叫做Everything, 号称是速度最快的文件名搜索工具；其实就是因为在NTFS系统下，所有文件目录和文件的meta信息都存放在一个叫做MFT文件里面，只需要获取到这里面的信息，就可以快速获取到NTFS分区里面的文件树信息了，是不是快了很多？</p>

<p>还有一些，时间久远，不太想得起来了，后面慢慢加 :)</p>

<h2>三 随机存取备份文件改进文件提取性能</h2>

<p>问题描述：需要从磁盘备份数据里面找到某个文件然后还原出来。。。
之前的版本：从备份文件里面展示出所有文件大概需要一个多小时，然后找到这个文件后还原，大概需要两个小时，而且内存和CPU都占满了
原因：之前是不支持随机存取，然后要展示所有的文件，差不多需要把整个磁盘备份解压缩一遍，然后找到文件还原的时候需要解压缩两遍，囧。。。
改进：以NTFS文件系统为例啦，有个MFT(Master File Table)文件，它里面每一项呢，都代表一个文件，然后MFT呢，本身也是一个特殊的文件，其实大家可以把它想象成为一本书的目录啦，只不过有个特殊的是，这个目录(MFT)的内容，并不是固定在某一个区域里的，而是可能分散在分区的任何一处的。所以之前的做法相当于是，先把整本书翻了一遍，然后将目录信息取出来了；然后找到某个文件的时候呢，又把整本书翻了一遍找到某个文件对应的目录信息，然后呢，再把整本书翻了一遍取到这个文件的信息。忘了说了，NTFS文件系统的特殊性还包括，这个文件的后半部分在磁盘上的位置可能更前，这样的话，可能还得从头把这本书翻一遍。
解决方案：其实就是允许随机存取备份生成的文件；对备份前的磁盘分块，通过改进文件格式，在已备份信息中记录类似MFT的信息，例如，所有待备份的都以2MB的大小分块，那么只要能够从备份生成的文件中快速找到要还原的文件是分布在哪些2MB块里面，就可以找到这些信息在备份文件里的偏移量，只需要解压缩这部分数据就可以了。比如说，先取目录信息(MFT)的时候，只需要取这个MFT文件对应的offset的内容进行解压缩，甚至可以做到，只取第一层目录；然后每个文件都能够找到它的对应内容处在备份文件的哪一块，再也不需要从头开始解压缩了。</p>

<p>其实，上面这些基本上都不需要什么特殊的算法知识，很多时候都是具体分析瓶颈在那里，尤其是在数据规模大的时候；而常见的性能改进方法，无非就是多线程、缓存、随机存取等等。</p>

<p>待续&hellip;.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[让人崩溃的bug]]></title>
    <link href="http://agger0207.github.io/blog/2015/11/27/rang-ren-beng-kui-de-bug/"/>
    <updated>2015-11-27T14:36:39+08:00</updated>
    <id>http://agger0207.github.io/blog/2015/11/27/rang-ren-beng-kui-de-bug</id>
    <content type="html"><![CDATA[<h2>一 iOS使用不规范造成的首页白屏</h2>

<p>WebView页面被遮挡，然后被Remove掉的时候，页面内容没有渲染出来</p>

<h2>二 人家的bug</h2>

<p>H5页面的bug, iOS开发工程师来帮忙调, 最怕的是Android还没问题(其实是Andorid也有问题，负负得正)</p>

<h2>三 人家的bug: Andorid内存溢出</h2>

<h2>四 花费时间最长的两个bug</h2>

<p>1 磁盘还原后某个文件内容不正确
2 磁盘还原后系统无法启动</p>

<h2>五 多线程</h2>

<p>多线程永远都是最头痛的问题, 死锁，Crash等等</p>

<h2>六 按键精灵</h2>

<h2>七 无法重现</h2>

<h2>八 客户报过来的</h2>

<p>有dump就不怕:)</p>

<p>之前CodeProject上有文章介绍在VC 6.0下如何根据crash日志定位到具体的代码行，在VS2010下其实也可用，不过有的时候对应不到代码行，只能到函数，这个时候，函数写的短小精悍的好处就出来了：）</p>

<h2>九 内存泄漏</h2>

<h2>十 已经改好了</h2>

<p>总结：代码Review, 静态代码分析，XCode Instruments能够很好的避免bug的出现;</p>

<p>待完善 （年纪大了，很多都已经不记得了，不过iOS相对来说更简单一些，至少多线程的问题少很多；代码量相对比较少也可以通过代码比对的方式来修正错误；一般如果是自己团队开发造成的bug都可以通过规范代码的方式来避免，除非crash在系统控件内部且无法重现）</p>

<p>吐槽：很多开发同学只要不是自己负责代码的bug就一概忽略；自己重现不了的bug一概忽略；其实，很多稍微调试一下或者稍微看看代码就能够知道问题所在；或者搜索下错误信息；或者搜索下最近代码改动；或者看下相关功能的代码；绝大部分都能够定位到原因；少数不能定位到具体原因，也能够限制在少部分代码块中，而这部分代码块如果写法规范点，基本上就没啥问题了。
当然，我也遇到过不靠谱的测试，由于网络问题的原因，中国这边无法测试，然后对方测试后给出个bug, 就只有一个出错界面，操作步骤和日志也没有，而且还经常把记录好的错误日志清除掉，再也重现不了。。。。</p>

<p>当然，不排除部分问题确实很难查。对于出现的问题，我总记得之前的架构师说过的一句话：“Let me debug it !”</p>
]]></content>
  </entry>
  
</feed>
